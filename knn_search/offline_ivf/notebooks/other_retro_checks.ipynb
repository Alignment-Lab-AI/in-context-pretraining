{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "82"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dim_reduce checks\n",
    "import yaml\n",
    "\n",
    "conf_file = \"/private/home/marialomeli/faiss_improvements/offline_ivf/config_retro.yaml\"\n",
    "with open(conf_file, \"r\") as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "\n",
    "# retro 4B\n",
    "shard_size = 100_000_000  # ~100GB\n",
    "embeddings_bs = 100_000\n",
    "bs = shard_size // embeddings_bs  # 1000\n",
    "nshards = cfg[\"datasets\"][\"retro_4B\"][\"size\"] // shard_size + 1\n",
    "# dt_4B = cfg\n",
    "print(nshards)\n",
    "\n",
    "# retro 8B, we added the extra train10.json to retro 4B plus the train11 to train19, each are split in 1024 chunks\n",
    "shard_size = 100_000_000  # ~100GB\n",
    "embeddings_bs = 100_000\n",
    "nshards = cfg[\"datasets\"][\"retro_8B\"][\"size\"] // shard_size + 1\n",
    "nshards\n",
    "\n",
    "# shard_size and embeddings_bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def read_embeddings(root, filename, file_format, dt, size, input_d):\n",
    "    fn = f\"{root}/{filename}\"\n",
    "    assert os.path.exists(fn)\n",
    "    if file_format == \"raw\":\n",
    "        fl = os.path.getsize(fn)\n",
    "        nb = fl // input_d // dt.itemsize\n",
    "        assert nb == size\n",
    "        assert fl == input_d * dt.itemsize * nb\n",
    "        return np.memmap(fn, shape=(nb, input_d), dtype=dt, mode=\"r\")\n",
    "    elif file_format == \"npy\":\n",
    "        vecs = np.load(fn, mmap_mode=\"r\")\n",
    "        assert vecs.shape[0] == size\n",
    "        assert vecs.shape[1] == input_d\n",
    "        assert vecs.dtype == dt\n",
    "        return vecs\n",
    "    else:\n",
    "        assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot load file containing pickled data when allow_pickle=False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [36], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mroot\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      8\u001b[0m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mroot\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m vecs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(fn, mmap_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/numpy/lib/npyio.py:457\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    455\u001b[0m     \u001b[39m# Try a pickle\u001b[39;00m\n\u001b[1;32m    456\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_pickle:\n\u001b[0;32m--> 457\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCannot load file containing pickled data \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    458\u001b[0m                          \u001b[39m\"\u001b[39m\u001b[39mwhen allow_pickle=False\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    459\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    460\u001b[0m         \u001b[39mreturn\u001b[39;00m pickle\u001b[39m.\u001b[39mload(fid, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_kwargs)\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot load file containing pickled data when allow_pickle=False"
     ]
    }
   ],
   "source": [
    "root = \"/checkpoint/hcir/data/retro-z/repo\"\n",
    "filename = (\n",
    "    \"dataset_name=1t/tokenizer=bert-base-cased/seq_len=2048/chunk_len=64/model=bert-base-cased/train00.jsonl.lz4.npy\"\n",
    ")\n",
    "format = \"npy\"\n",
    "list_of_files = cfg[\"datasets\"][\"retro_8B\"][\"files\"]\n",
    "size = list_of_files[0][\"size\"]\n",
    "dt = np.dtype(list_of_files[0][\"dtype\"])\n",
    "fn = f\"{root}/{filename}\"\n",
    "os.path.exists(f\"{root}/{filename}\")\n",
    "# vecs = np.load(fn, mmap_mode='r')\n",
    "# read_embeddings(root,filename,format,dt,size,768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train10.jsonl.lz4.npy']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[f\"train{i:02}.jsonl.lz4.npy\" for i in range(10, 11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18791543808 18791543808\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "file = \"/checkpoint/hcir/data/retro-z/repo/dataset_name=edouard_val/tokenizer=bert-base-cased/seq_len=2048/chunk_len=64/model=bert-base-cased/val.jsonl.lz4.npy\"\n",
    "fl = os.path.getsize(file)\n",
    "dt = np.dtype(np.float16)\n",
    "nb = fl // 768 // dt.itemsize\n",
    "print(768 * dt.itemsize * nb, fl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/checkpoint/marialomeli/offline_faiss/test_data/my_data00.npy\n",
      "/checkpoint/marialomeli/offline_faiss/test_data/my_data01.npy\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import faiss\n",
    "\n",
    "results = \"/checkpoint/marialomeli/offline_faiss/retro/edouard_val_in_retro_4B/I0000000000.npy\"\n",
    "indices = np.load(results)\n",
    "indices.shape  # we can check if the neighbours are the right number\n",
    "index = \"/checkpoint/marialomeli/offline_faiss/retro/retro_8B/OPQ128_512_IVF4096_PQ128.faissindex\"\n",
    "loaded = faiss.read_index(index)\n",
    "index_ivf = faiss.downcast_index(faiss.extract_index_ivf(loaded))\n",
    "index_ivf.nprobe\n",
    "index_ivf.ntotal\n",
    "index_ivf.is_trained\n",
    "index_ivf.code_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
